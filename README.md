# Project--Hadoop-32

<table>
  
**In this project We will use Spark with Python to do an amazing stuff. We have used spark streaming to count the total number of status code in the log folder with window interval of 30 seconds and slide interval of 15 seconds in access_log.txt file**.<br></br>

**Before jumping to the code lets understand Spark first**...<br></br>

**What is Apache Spark**?<br></br>

Apache Spark is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.
Apache Spark is an open-source unified analytics engine for large-scale data processing. Spark provides an interface for programming clusters with implicit data parallelism and fault tolerance.<br></br>

**What is Spark Streaming**?<br></br>
Spark Streaming is the previous generation of Spark’s streaming engine. There are no longer updates to Spark Streaming and it’s a legacy project. There is a newer and easier to use streaming engine in Spark called Structured Streaming. You should use Spark Structured Streaming for your streaming applications and pipelines.<br></br>



**Important Note: Go through the access_log.txt before jumping to the code.**

</table>

**So what are you waiting for...? Jump to the code to get started. As usual for any doubt or query see you in pull request section 😁😂. Thanks!**
